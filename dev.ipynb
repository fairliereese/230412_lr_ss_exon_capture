{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "65e7c248-b802-4754-b1e6-c56f620f556c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from snakemake.io import expand\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import pdb\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a216c289-1ca5-4b94-a65b-68c765bd1721",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'config.yml'\n",
    "with open(config_file) as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7fca0a71-00f1-4e4c-ba97-fc979ba3c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_config_file(fname, auto_dedupe=True):\n",
    "    df = pd.read_csv(fname, sep='\\t')\n",
    "    \n",
    "    # get flowcell \n",
    "    exp = '.*\\/[\\w-]+_(\\d+)(?:_t\\d+)?\\.fastq(?:.gz)?'\n",
    "    df['flowcell'] = df.fname.str.extract(exp)\n",
    "\n",
    "    # get dataset\n",
    "    exp = '.*\\/[\\w-]+_(\\d+[ABCDEFGH])[\\w-]+\\d+(?:_t\\d+)?\\.fastq(?:.gz)?'\n",
    "    df['dataset'] = df.fname.str.extract(exp)\n",
    "\n",
    "\n",
    "    # check to make sure the same file stem isn't there more than once \n",
    "    # (can happen if different flow cells needed different amounts of chopping)\n",
    "    # df['file_stem'] = df.basename.str.rsplit('_', n=1, expand=True)[0]\n",
    "    exp = '.*\\/([\\w-]+_\\d+)(?:_t\\d+)?\\.fastq(?:.gz)?'\n",
    "    df['file_stem'] = df.fname.str.extract(exp)\n",
    "    df['chop_num'] = df.basename.str.rsplit('.fastq', expand=True)[0].str.rsplit('_t', expand=True)[1].astype(float)\n",
    "    if df.file_stem.duplicated().any():\n",
    "        dupe_stems = df.loc[df.file_stem.duplicated(keep=False), 'basename'].tolist()    \n",
    "        if not auto_dedupe:\n",
    "            raise ValueError(f'Files {dupe_stems} seem to be duplicated. Check config file.')\n",
    "        else:\n",
    "            print(f'Files {dupe_stems} seem to be duplicated. Automatically removing lower chop numbers')\n",
    "            df = df.sort_values(by='chop_num', ascending=False)\n",
    "            df = df.drop_duplicates(subset='file_stem', keep='first')\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6fe9a07f-ede8-4e07-85a8-1dc9d55f9cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('230427_config.tsv', sep='\\t')\n",
    "print(len(df.index))\n",
    "\n",
    "auto_dedupe = True\n",
    "\n",
    "# get flowcell \n",
    "exp = '.*\\/[\\w-]+_(\\d+)(?:_t\\d+)?\\.fastq(?:.gz)?'\n",
    "df['flowcell'] = df.fname.str.extract(exp)\n",
    "\n",
    "# get dataset\n",
    "exp = '.*\\/[\\w-]+_(\\d+[ABCDEFGH])[\\w-]+\\d+(?:_t\\d+)?\\.fastq(?:.gz)?'\n",
    "df['dataset'] = df.fname.str.extract(exp)\n",
    "\n",
    "\n",
    "# check to make sure the same file stem isn't there more than once \n",
    "# (can happen if different flow cells needed different amounts of chopping)\n",
    "# df['file_stem'] = df.basename.str.rsplit('_', n=1, expand=True)[0]\n",
    "exp = '.*\\/([\\w-]+_\\d+)(?:_t\\d+)?\\.fastq(?:.gz)?'\n",
    "df['file_stem'] = df.fname.str.extract(exp)\n",
    "df['chop_num'] = df.basename.str.rsplit('.fastq', expand=True)[0].str.rsplit('_t', expand=True)[1].astype(float)\n",
    "if df.file_stem.duplicated().any():\n",
    "    dupe_stems = df.loc[df.file_stem.duplicated(keep=False), 'basename'].tolist()    \n",
    "    if not auto_dedupe:\n",
    "        raise ValueError(f'Files {dupe_stems} seem to be duplicated. Check config file.')\n",
    "    else:\n",
    "        print(f'Files {dupe_stems} seem to be duplicated. Automatically removing lower chop numbers')\n",
    "        df = df.sort_values(by='chop_num', ascending=False)\n",
    "        df = df.drop_duplicates(subset='file_stem', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37b52341-0837-47f1-9c30-35f290168c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('config.tsv', sep='\\t')\n",
    "df = pd.read_csv('230427_config.tsv', sep='\\t')\n",
    "cols = ['fname', 'sample',\n",
    "        'dataset', 'platform',\n",
    "        'flowcell']\n",
    "for c in cols:\n",
    "    df[c] = df[c].astype(str)\n",
    "    \n",
    "# subset the config df on dataset\n",
    "def get_df_dataset(dataset, df):\n",
    "    return df.loc[df.dataset==dataset]\n",
    "\n",
    "# subset the config df on flowcell\n",
    "def get_df_flowcell(flowcell, df):\n",
    "    return df.loc[df.flowcell==flowcell]\n",
    "\n",
    "# get a 1:1 value for dataset:<col> from config\n",
    "def get_df_dataset_val(wc, df, col):\n",
    "    temp = get_df_dataset(wc.dataset, df)\n",
    "    return temp[col].values[0]\n",
    "\n",
    "# get a 1:many value (ie dataset:flowcell, dataset:fname) from config\n",
    "def get_df_dataset_col(wc, df, col):\n",
    "    temp = get_df_dataset(wc.dataset, df)\n",
    "    return temp[col].tolist()\n",
    "\n",
    "# get a 1:1 value from flowcell,dataset:<col>\n",
    "def get_df_dataset_flowcell_col(dataset, flowcell, df, col):\n",
    "    temp = get_df_dataset(dataset, df)\n",
    "    temp = get_df_flowcell(flowcell, temp)\n",
    "    return temp[col].values[0]\n",
    "\n",
    "# def get_df_col(wc, df, col):\n",
    "#     val = df.loc[df.dataset==wc.dataset, col].values[0]\n",
    "#     return val\n",
    "#\n",
    "# def get_df_whole_col(wc, df, col):\n",
    "#     temp = df.loc[df.dataset==wc.dataset]\n",
    "#     if flowcell in wc.keys():\n",
    "#         temp = df.loc[df.flowcell==wc.flowcell]\n",
    "#     vals = temp[col].tolist()\n",
    "#     return vals\n",
    "\n",
    "def get_sublib_bc_files(wc, df, config):\n",
    "    sublib_flowcells = get_df_dataset_col(wc, df, 'flowcell')\n",
    "    bc_files = expand(config['proc']['demux_bc'],\n",
    "                      dataset=wc.dataset,\n",
    "                      flowcell=sublib_flowcells)\n",
    "    return bc_files\n",
    "\n",
    "files = df['fname'].tolist()\n",
    "samples = df['sample'].astype(str).tolist()\n",
    "datasets = df['dataset'].astype(str).tolist()\n",
    "platforms = df['platform'].astype(str).tolist()\n",
    "flowcells = df['flowcell'].astype(str).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bcd1d808-192c-4658-84a6-06a41bc893f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/share/crsp/lab/seyedam/share/igvf_nanopore/igvfb01/igvfb01_13G-gc_lig-ss_1_t2.fastq.gz'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_df_dataset_flowcell_col('13G', '1', df, 'fname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fac491-44fa-417b-a131-cd1cfb7ea3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384c398e-957a-4e12-9df9-7ec4d4ceb4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
